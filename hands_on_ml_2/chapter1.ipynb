{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning?\n",
    "\n",
    " - 데이터에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학.\n",
    " - 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야.\n",
    " - 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 이해 성능이 향상됐다면,\n",
    "   이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Dataset\n",
    "\n",
    "시스템이 학습하는 데 사용하는 샘플을 **훈련 세트(Training Set)**이라 하고,  \n",
    "각 훈련 데이터를 **훈련사례(Training Instance)** 혹은 훈련 샘플이라 한다.\n",
    "\n",
    "### 개인적인 이해를 통해 설명하자면, (개인적으로 이렇게 이해를 한 것으로 틀렸을 수도 있다.)\n",
    "\n",
    "예로, Cat이냐 Dog냐를 분류(classification)하는 Model을 만들고자 한다.  \n",
    "우리가 가진 Dataset은 Train이라는 폴더 내에 각각 cats, dogs 폴더 2개가 존재하고  \n",
    "cats 폴더안에는 cats_01.jpg, cats_02.jpg ...  \n",
    "dogs 폴더안에는 dogs_01.jpg, dogs_02.jpg ...  \n",
    "\n",
    "이렇게 구성된 dataset이 존재할 때 앞서 언급된 내용들을 적용해보면,\n",
    "             \n",
    " - 학습하는데 사용하는 샘플인 훈련 세트(Training Set)이 Train에 해당하고,\n",
    " - 각 훈련 데이터 훈련사례(Training Instance)는 cat_01.jpg, cat_02.jpg 각각을 의미하는 것 같다.\n",
    "\n",
    "스팸 메일 필터의 경우,\n",
    " - 작업 T는 새로운 메일이 스팸인지 구분하는 것\n",
    " - 경험 E는 훈련 데이터(Training Data)\n",
    " - 성능 측정 P는 한 예로 정확도(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why we use ML?\n",
    "\n",
    "머신러닝을 사용하는 이유가 무엇일까?  \n",
    "\n",
    " 1. 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제를 하나의 ML model이 코드를 간단하게 만들고 더 좋은 성능을 발휘한다.  \n",
    " hard coding을 통해서 스팸메일에 자주 등장하는 단어들을 감지하는 알고리즘을 작성해서 패턴을 감지해야 하는 방식과 달리, 학습 데이터를 구축하고 학습한 model을 이용해 간편하게 패턴을 감지할 수 있게 된다.  \n",
    "\n",
    " 2. 확장성이 용이하다. 새로운 데이터에 적응할 수 있다.  \n",
    "    추가적인 스팸 단어가 생겼을 때, coding을 이용해 감지하는 것은 알고리즘에 추가적인 수정 및 조정하는 비용이 발생하지만,\n",
    "    ML model은 학습 데이터로 추가만 해주면 손쉽게 그 범용성을 확장 시킬 수 있다.  \n",
    "        \n",
    " 3. 해결 방법이 없는 복잡한 문제 역시 ML 기법을 통해 해결 방법을 찾을 수 있다.  \n",
    "     예로 비정형 데이터들로 구성된 데이터셋이 있고, 이를 분석해낼 전문가 역시 없다고 가정하면, 이 비정형 데이터들 속에서 의미있는 패턴을 예측해 낼 수 있게 된다.(이를 Data Mining이라 한다)  \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of machine learning systems\n",
    "넓은 범주에서 분류해보면 ML 방식은 다음과 같이 구분할 수 있다.  \n",
    "\n",
    "1. 사람의 감독하에 훈련하는 것인가(Supervised Learning). 그렇지 않은가(Unsupervised Learning)  \n",
    "  \n",
    "2. 실시간으로 점진적인 학습을 하는지(Online Learning) 아닌지(Offline Learning)  \n",
    " \n",
    "3. 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지(Instance based Learning) 아니면 과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지(Model based Learning)  \n",
    " \n",
    "이 범주들은 서로 배타적이지 않으며 원하는 대로 연결할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Supervised Learning과 Unsupervised Learning\n",
    "\n",
    "1-1 **지도 학습 Supervised Learning**에는 알고리즘에 주입하는 훈련 데이터에 __label이라는 원하는 정답이 포함__된다.  \n",
    " - 분류(Classification)가 전형적인 지도학습에 속함.\n",
    " - 회귀(Regression)도 지도학습에 속하는데,    \n",
    "   이는 예측 변수(predictor variable)라 부르는 특성(feature)을 사용해 중고차 가격 같은 target 수치를 예측 하는 것    \n",
    "   ML에서 속성(Attribute)는 데이터 타입(예로 주행거리)를 뜻함. 특성(Feature)는 일반적으로 속성과 값이 합쳐진 것.(주행거리=15,000)\n",
    "   \n",
    "   \n",
    "1-2 **비지도 학습 Unsupervised Learning**에는 말 그대로 **훈련데이터에 label이 없다. 즉, 정답이 포함되지 않음.**\n",
    "- 시스템이 아무런 도움 없이 알아서 데이터간의 연결고리를 찾아야 한다.\n",
    "- 예로 블로그 방문자에 대한 데이터가 있다고 가정.   \n",
    "  비슷한 방문자들을 그룹으로 묶기 위해 군집 알고리즘을 적용하려고 한다.\n",
    "  그러나, 방문자가 어떤 그룹에 속하는지 알고리즘에 알려줄 수 있는 데이터 포인트가 없음.(label이 없으니까)\n",
    "  결국 알고리즘이 스스로 방문자 사이의 연관성을 찾아야 한다.\n",
    "      \n",
    "    \n",
    "1-3 **준지도 학습 Semisupervised Learning**은 일부만 label이 있는 데이터를 통해 학습.\n",
    "\n",
    "\n",
    "1-4 **강화 학습 Reinforcement Learning**\n",
    "- 학습하는 시스템을 에이전트(Agent)라고 부르며 환경(Environment)을 관찰해서 행동(Action)을 실행하고 그 결과로 보상(Reward)을 받음.\n",
    "- 시간이 지나면서 가장 큰 보상을 얻기 위해 정책(policy)이라 부르는 최상의 전략을 스스로 학습."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Batch Learning과 Online Learning\n",
    "ML 시스템을 분류하는 데 사용하는 다른 기준은 입력 데이터의 스트림(stream)부터 점진적으로 학습할 수 있는지 여부.\n",
    "\n",
    "2-1 배치 학습(Batch Learning)    \n",
    "- 시스템이 점진적으로 학습할 수 없다. 즉, 가지고 있는 모든 Train data를 사용해 Training해야함.\n",
    "- 시간과 자원을 많이 소모하므로 보통 offline에서 수행.\n",
    "- 시스템을 훈련시키고 제품 시스템에 적용하면 더 이상의 학습없이 실행됨. 즉, 학습한 것을 단지 적용만함.이를 offline learning이라고 한다.\n",
    "- 배치 학습이 새로운 데이터에 대해 학스바려면 새로운 데이터 + 이전 데이터를 이용해 새로운 버전을 처음부터 다시 훈련해야함.\n",
    "- 데이터 수가 너무 많아서 용량이 커질 경우 비용이 매우 커질 수 있으며, 배치 학습이 아예 불가능할 수도 있음.\n",
    "    \n",
    "    \n",
    "2-2 온라인 학습(Online Learning)\n",
    "- 온라인 학습에서는 데이터를 순차적으로 한 개씩 또는 미니배치(Mini-batch)라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킴.     \n",
    "- 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있다.\n",
    "- 즉, 온라인 학습에서 모델을 훈련하고 제품에 런칭한 뒤에도 새로운 데이터가 들어오면 계속 학습.\n",
    "- 연속적으로 데이터를 받고, 빠른 변화에 스스로 적응해야하는 시스템에 적합. 컴퓨팅 자원이 제한된 경우에도 좋은 선택.\n",
    "- 새로운 데이터 샘플을 학습하면 학습이 끝난 데이터는 버리게 됨. 메모리 공간 절약에 용이.\n",
    "- __학습률(Learning Rate)__이란 변화하는 데이터에 얼마나 빠르게 적응할 것인가    \n",
    "    학습률이 높은 경우 빠르게 새로운 데이터에 적응하되, 예전 데이터를 금방 잊어버릴 것.    \n",
    "    낮은 경우에는 시스템의 관성이 더 켜져서 더 느리게 학습될 것. 잡음이나 대표성이 없는 데이터 포인트에 덜 민감해짐.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 사례 기반 학습과 모델 기반 학습\n",
    "ML 시스템은 어떻게 일반화(generalize) 되는가에 따라 분류 할 수도 있다.    \n",
    "대부분의 머신러닝 작업은 예측을 만드는 것으로, 훈련데이터로 학습하고 **훈련데이터에서 본 적 없는 새로운 데이터에서 좋은 예측을 만들어야 한다**는 뜻.\n",
    "\n",
    "3-1 사례 기반 학습(Instance-based Learning)\n",
    "- 스팸메일과 일반메일 사이의 유사도(similarity)를 측정. 스팸메일과 공통으로 가지고 있는 단어가 많으면 스팸으로 분류.\n",
    "- 시스템이 훈련 샘플을 기억함으로써 학습. 그리고 유사도 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화.\n",
    "\n",
    "3-2 모델 기반 학습(Model-based Learning)\n",
    "- 샘플들의 모델을 만들어 예측에 사용하는 것\n",
    "- 예로 삶의 만족도는 국가의 1인당 GDP가 증가할 수록 거의 선형으로 올라간다.   \n",
    "  따라서 1인당 GDP의 선형 함수로 삶의 만족도를 모델링 한다 할때, 이 단계를 모델 선택이라함.    \n",
    "  (개인적으로 이해한 것은 데이터들로부터 어떤 특정한 모델을 설정(가설을 설정)하는 것이라 이해)\n",
    "  ![sample img](doc_img/chapter1_1.png)\n",
    "- 이후 대해 test data가 들어왔을 때, 모델이 얼마나 좋은지 측정하는 효용 함수(utility function), 얼마나 나쁜지 측정하는 비용 함수(cost function)으로 결과치를 측정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
    "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
    "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
    "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
    "                                  left_index=True, right_index=True)\n",
    "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
    "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
    "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
    "    return full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading oecd_bli_2015.csv\nDownloading gdp_per_capita.csv\n"
    }
   ],
   "source": [
    "import os\n",
    "datapath = os.path.join(\"datasets\", \"lifesat\", \"\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import urllib\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/rickiepark/handson-ml2/master/\"\n",
    "os.makedirs(datapath, exist_ok=True)\n",
    "for filename in (\"oecd_bli_2015.csv\", \"gdp_per_capita.csv\"):\n",
    "    print(\"Downloading\", filename)\n",
    "    url = DOWNLOAD_ROOT + \"datasets/lifesat/\" + filename\n",
    "    urllib.request.urlretrieve(url, datapath + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli = pd.read_csv('/data/backup/pervinco_2020/hands_on_ml/datasets/lifesat/oecd_bli_2015.csv', thousands=',')\n",
    "gdp_per_capita = pd.read_csv('/data/backup/pervinco_2020/hands_on_ml/datasets/lifesat/gdp_per_capita.csv',\n",
    "                             thousands=',', delimiter='\\t',\n",
    "                             encoding='latin1', na_values='n/a')\n",
    "\n",
    "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
    "X = np.c_[country_stats[\"GDP per capita\"]]\n",
    "y = np.c_[country_stats[\"Life satisfaction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"268.003125pt\" version=\"1.1\" viewBox=\"0 0 392.833125 268.003125\" width=\"392.833125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 268.003125 \nL 392.833125 268.003125 \nL 392.833125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.833125 224.64 \nL 385.633125 224.64 \nL 385.633125 7.2 \nL 50.833125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 2.236068 \nC 0.593012 2.236068 1.161816 2.000462 1.581139 1.581139 \nC 2.000462 1.161816 2.236068 0.593012 2.236068 0 \nC 2.236068 -0.593012 2.000462 -1.161816 1.581139 -1.581139 \nC 1.161816 -2.000462 0.593012 -2.236068 0 -2.236068 \nC -0.593012 -2.236068 -1.161816 -2.000462 -1.581139 -1.581139 \nC -2.000462 -1.161816 -2.236068 -0.593012 -2.236068 0 \nC -2.236068 0.593012 -2.000462 1.161816 -1.581139 1.581139 \nC -1.161816 2.000462 -0.593012 2.236068 0 2.236068 \nz\n\" id=\"m62c1bd745f\" style=\"stroke:#1f77b4;\"/>\n    </defs>\n    <g clip-path=\"url(#p45243794fc)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"66.05135\" xlink:href=\"#m62c1bd745f\" y=\"126.818797\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"68.541309\" xlink:href=\"#m62c1bd745f\" y=\"155.882255\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"86.786876\" xlink:href=\"#m62c1bd745f\" y=\"206.743306\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"88.449895\" xlink:href=\"#m62c1bd745f\" y=\"141.350526\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"111.212905\" xlink:href=\"#m62c1bd745f\" y=\"119.552932\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"119.652655\" xlink:href=\"#m62c1bd745f\" y=\"155.882255\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"124.706068\" xlink:href=\"#m62c1bd745f\" y=\"214.009171\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"131.58955\" xlink:href=\"#m62c1bd745f\" y=\"192.211577\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"142.077104\" xlink:href=\"#m62c1bd745f\" y=\"148.61639\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"175.490084\" xlink:href=\"#m62c1bd745f\" y=\"90.489474\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"184.152028\" xlink:href=\"#m62c1bd745f\" y=\"141.350526\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"201.543833\" xlink:href=\"#m62c1bd745f\" y=\"126.818797\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"218.594362\" xlink:href=\"#m62c1bd745f\" y=\"134.084661\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"237.199752\" xlink:href=\"#m62c1bd745f\" y=\"25.096694\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"248.277573\" xlink:href=\"#m62c1bd745f\" y=\"32.362558\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"252.37988\" xlink:href=\"#m62c1bd745f\" y=\"90.489474\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"268.210762\" xlink:href=\"#m62c1bd745f\" y=\"61.426016\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"274.004239\" xlink:href=\"#m62c1bd745f\" y=\"54.160152\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"280.368015\" xlink:href=\"#m62c1bd745f\" y=\"25.096694\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"289.208975\" xlink:href=\"#m62c1bd745f\" y=\"32.362558\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"290.974299\" xlink:href=\"#m62c1bd745f\" y=\"32.362558\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"291.761512\" xlink:href=\"#m62c1bd745f\" y=\"61.426016\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"292.065268\" xlink:href=\"#m62c1bd745f\" y=\"68.691881\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"331.749979\" xlink:href=\"#m62c1bd745f\" y=\"39.628423\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"338.184328\" xlink:href=\"#m62c1bd745f\" y=\"17.830829\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"338.882778\" xlink:href=\"#m62c1bd745f\" y=\"32.362558\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"341.414539\" xlink:href=\"#m62c1bd745f\" y=\"54.160152\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"346.384723\" xlink:href=\"#m62c1bd745f\" y=\"17.830829\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"370.4149\" xlink:href=\"#m62c1bd745f\" y=\"39.628423\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mc2318d13b9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"72.204248\" xlink:href=\"#mc2318d13b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 10000 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(53.116748 240.758125)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"137.308346\" xlink:href=\"#mc2318d13b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20000 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(118.220846 240.758125)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"202.412445\" xlink:href=\"#mc2318d13b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 30000 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(183.324945 240.758125)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"267.516544\" xlink:href=\"#mc2318d13b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 40000 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(248.429044 240.758125)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"332.620642\" xlink:href=\"#mc2318d13b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 50000 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(313.533142 240.758125)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- GDP per capita -->\n     <defs>\n      <path d=\"M 59.515625 10.40625 \nL 59.515625 29.984375 \nL 43.40625 29.984375 \nL 43.40625 38.09375 \nL 69.28125 38.09375 \nL 69.28125 6.78125 \nQ 63.578125 2.734375 56.6875 0.65625 \nQ 49.8125 -1.421875 42 -1.421875 \nQ 24.90625 -1.421875 15.25 8.5625 \nQ 5.609375 18.5625 5.609375 36.375 \nQ 5.609375 54.25 15.25 64.234375 \nQ 24.90625 74.21875 42 74.21875 \nQ 49.125 74.21875 55.546875 72.453125 \nQ 61.96875 70.703125 67.390625 67.28125 \nL 67.390625 56.78125 \nQ 61.921875 61.421875 55.765625 63.765625 \nQ 49.609375 66.109375 42.828125 66.109375 \nQ 29.4375 66.109375 22.71875 58.640625 \nQ 16.015625 51.171875 16.015625 36.375 \nQ 16.015625 21.625 22.71875 14.15625 \nQ 29.4375 6.6875 42.828125 6.6875 \nQ 48.046875 6.6875 52.140625 7.59375 \nQ 56.25 8.5 59.515625 10.40625 \nz\n\" id=\"DejaVuSans-71\"/>\n      <path d=\"M 19.671875 64.796875 \nL 19.671875 8.109375 \nL 31.59375 8.109375 \nQ 46.6875 8.109375 53.6875 14.9375 \nQ 60.6875 21.78125 60.6875 36.53125 \nQ 60.6875 51.171875 53.6875 57.984375 \nQ 46.6875 64.796875 31.59375 64.796875 \nz\nM 9.8125 72.90625 \nL 30.078125 72.90625 \nQ 51.265625 72.90625 61.171875 64.09375 \nQ 71.09375 55.28125 71.09375 36.53125 \nQ 71.09375 17.671875 61.125 8.828125 \nQ 51.171875 0 30.078125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-68\"/>\n      <path d=\"M 19.671875 64.796875 \nL 19.671875 37.40625 \nL 32.078125 37.40625 \nQ 38.96875 37.40625 42.71875 40.96875 \nQ 46.484375 44.53125 46.484375 51.125 \nQ 46.484375 57.671875 42.71875 61.234375 \nQ 38.96875 64.796875 32.078125 64.796875 \nz\nM 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.34375 72.90625 50.609375 67.359375 \nQ 56.890625 61.8125 56.890625 51.125 \nQ 56.890625 40.328125 50.609375 34.8125 \nQ 44.34375 29.296875 32.078125 29.296875 \nL 19.671875 29.296875 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-80\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     </defs>\n     <g transform=\"translate(165.559219 257.891562)scale(0.14 -0.14)\">\n      <use xlink:href=\"#DejaVuSans-71\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-68\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"214.794922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"246.582031\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"310.058594\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"371.582031\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"412.695312\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"444.482422\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"499.462891\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"560.742188\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"624.21875\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"652.001953\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"691.210938\" xlink:href=\"#DejaVuSans-97\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m2eaf4ed448\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.833125\" xlink:href=\"#m2eaf4ed448\" y=\"199.477442\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 5.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(24.749375 204.036504)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.833125\" xlink:href=\"#m2eaf4ed448\" y=\"163.148119\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5.5 -->\n      <g transform=\"translate(24.749375 167.707182)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.833125\" xlink:href=\"#m2eaf4ed448\" y=\"126.818797\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 6.0 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(24.749375 131.377859)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.833125\" xlink:href=\"#m2eaf4ed448\" y=\"90.489474\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 6.5 -->\n      <g transform=\"translate(24.749375 95.048537)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.833125\" xlink:href=\"#m2eaf4ed448\" y=\"54.160152\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 7.0 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(24.749375 58.719214)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.833125\" xlink:href=\"#m2eaf4ed448\" y=\"17.830829\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 7.5 -->\n      <g transform=\"translate(24.749375 22.389892)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- Life satisfaction -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n      <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(17.837812 171.043906)rotate(-90)scale(0.14 -0.14)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"55.712891\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"83.496094\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"118.701172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"180.224609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"212.011719\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"264.111328\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"325.390625\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"364.599609\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"392.382812\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"444.482422\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"479.6875\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"540.966797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"595.947266\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"635.15625\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"662.939453\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"724.121094\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.833125 224.64 \nL 50.833125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 385.633125 224.64 \nL 385.633125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.833125 224.64 \nL 385.633125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.833125 7.2 \nL 385.633125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p45243794fc\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.833125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[5.96242338]]\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "X_new = [[22587]]\n",
    "print(model.predict(X_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 지금까지의 작업을 요약해보면 다음과 같다.\n",
    "1. 데이터에 대한 분석\n",
    "2. model을 선택\n",
    "3. train data로 모델을 training(학습 알고리즘이 비용 함수를 최소화하는 Parameter를 찾는다.)\n",
    "4. 새로운 데이터(Test-data)를 모델에 적용해 예측하고 해당 모델이 일반화가 잘되었는지 검증(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML's Challenge\n",
    "\n",
    "### 나쁜 데이터 사례\n",
    "\n",
    "1. 충분하지 않은 양의 훈련 데이터\n",
    "어린아이에게 사과에 대해 알려주면 사과를 가리키면서 '사과'라고 말하기만 하면 된다.(반복적으로 이 과정을 거칠 수도 있음.)    \n",
    "그러면 아이는 색상과 모양이 달라도 모든 종류의 사과를 구분할 수 있다.        \n",
    "ML은 아직 이렇게까지 할 수 없다. 많은 데이터를 갖추어서 제대로 된 학습을 해야만 정확하게 동작할 수 있다.        \n",
    "(개인적인 생각 - 데이터의 양이 많아질수록, Test data로 입력되는 것이 어떠한 것이든 정답을 출력할 수 있을 일반화가 더 강력하게 되는 것으로 생각.)    \n",
    "\n",
    "2. 대표성이 없는 훈련 데이터\n",
    "일반화가 잘되려면 우리가 일반화하기를 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요.    \n",
    "(개인적인 이해 : 어떤 label의 데이터가 자신을 표현하는 특성을 잘 나타내고 있는 양질의 데이터인가? 가 중요하다고 말하는 것 같음.)        \n",
    "앞서 1인당 GDP에 따른 삶의 만족도에서 예를 들어보면,\n",
    "![img](doc_img/chapter1_2.png)    \n",
    "선형 모델을 훈련시키기 위해 사용한 나라의 집합에는 일부 나라가 빠져 있어 대표성이 완벽하지 못하다.    \n",
    " - 기존데이터 + 누락된 데이터로 구성된 데이터로 선형 모델을 훈련시키면 검은색 실선으로 된 모델을 얻을 수 있고,    \n",
    " - 이전에 예제를 통해 얻은 모델은 파란색 점선으로 나타나 있다.\n",
    " - 결과를 보면 매우 부유한 나라가 중간 수준의 나라보다 행복하지 않고, 반대로 일부 가난한 나라가 부유한 나라보다 행복한 것을 볼 수 있다.\n",
    " - 즉 test data가 입력되었을 때, 모델의 예측에서 크게 벗어나는 결과를 나타나게 되고, 기존의 데이터들은 대표성이 없는 데이터들이었음을 알 수 있다.\n",
    " \n",
    " 일반화하려는 사례들을 대표하는 훈련세트를 사용하는 것(데이터가 특성을 잘나타내고 있는)이 중요하지만, 이것은 생각보다 어렵다.\n",
    " - 샘플이 작으면 샘플링 잡음(sampling noise) (우연에 의한 대표성이 없는 데이터)이 발생.\n",
    " - 매우 큰 샘플은 표본 추출 방법이 잘못되면 대표성을 가지지 못할 수 있음.    \n",
    " (개인적인 생각 : 그렇다면 결국 dataset은 큰 것이 좋으나, 이에 대해 정확한 feature extract이 적용되어야 한다는 뜻인가??)  \n",
    " \n",
    "3. 낮은 품질의 데이터\n",
    "훈련 데이터가 에러, 이상치, 잡음으로 가득하다면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않을 것이다.    \n",
    "자료 추가)여기서 **이상치(Outlier)란** 패턴에서 벗어난 값, 중심에서 많이 떨어져 있는 값이라 할 수 있다.  \n",
    "그렇기 때문에 Train data 정제에 시간을 투자할 가치는 충분하다.\n",
    " - 일부 샘플이 이상치라는게 명확하면 간단히 그것들을 무시하거나 수동으로 잘못된 것을 고치는 것이 좋다.\n",
    " - 일부 샘플에 특성 몇개가 빠져있다면(ex. 고객 중 5%가 나이를 등록하지 않음), 이 특성을 모두 무시할지, 이 샘플을무시할지, 빠진 값을 채울지, 또는 이 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬 것인지 결정해야한다.  \n",
    " \n",
    "4. 관련 없는 특성  \n",
    "훈련 데이터에 관련 없는 특성이 적고 관련 있는 특성이 충분해야 시스템이 학습할 수 있을 것이다.    \n",
    "성공적인 머신러닝 프로젝트의 핵심 요소는 사용할 좋은 특성들을 찾는 것이다. 이 과정을 특성 공학(Feature engineering)이라 하며 다음과 같은 작업이다.\n",
    " - 특성 선택(Feature selection) : 가지고 있는 특정 중에서 훈련에 가장 유용한 특성을 선택한다.\n",
    " - 특성 추출(Feature extraction) : 특성을 결합하여 더 유용한 특성을 만든다.\n",
    " - 새로운 데이터를 수집해서 새로운 특성을 만든다.  \n",
    " \n",
    "  **(개인적인 생각 : 그렇다면 지금 내가 하고 있는 Image Dataset들이 가지고 있는 Feature가 어떻게 구성되어 있는지, 어떻게 정제해야 하는지???)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나쁜 알고리즘 사례\n",
    "- 훈련 데이터 과대적합(Overfitting)  \n",
    "해외 여행 중 택시운전사가 내 물건을 훔쳤다고 가정하자. 아마 그 나라의 모든 택시운전사를 도둑으로 생각할 수 있다.  \n",
    "사람은 종종 과도하게 일반화를 하지만 주의하지 않으면 기계도 똑같은 함정에 빠질 수 있다.  \n",
    "ML에서는 이를 **과대적합(Overfitting)**이라고 한다. **이는 model이 훈련 데이터에 너무 잘맞지만 일반성이 떨어진다는 뜻이다.**\n",
    "\n",
    "  model이 training data에 잘 맞는다 하더라도 test data에 대한 예측 결과는 이상하게 더 낮게 나올 수 있음을 뜻함.\n",
    "  심층 신경망 같은 복잡한 모델은 데이터에서 미묘한 패턴을 감지할 수 있으나, 훈련 세트에 잡음이 많거나 데이터셋이 너무 작으면(샘플링 잡음이 발생) 잡음이 섞인 패턴을 감지하게 된다. 따라서 일반화도 제대로 되지 못함.\n",
    "  \n",
    "  예를 들어 삶의 만족도 모델에 나라 이름과 같은 관련 없는 특성을 많이 추가한다고 하면, 이 경우 복잡한 모델이 이름에 w가 들어간 나라들의 삶의 만족도가 7보다 크다는 패턴을 감지할 수 있다.\n",
    "  \n",
    "  또한 과대적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어난다. 이에 대한 해결법은 다음과 같다.\n",
    "  - 파라미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 **제약(Regularization)**을 가하여 단순화 시킨다.\n",
    "  - 훈련 데이터를 더 많이 모은다.\n",
    "  - 훈련 데이터의 잡음을 줄인다.(오류 데이터를 수정하거나, 이상치를 제거한다거나)\n",
    "  \n",
    "  학습하는 동안 적용할 규제의 양은 **하이퍼파라미터(hyperparameter)**가 결정한다. **이는 모델이 아니라 학습 알고리즘의 파라미터이다.**  \n",
    "  그래서 학습 알고리즘으로부터 영향을 받지 않으며, 훈련 전에 미리 지정되고, 훈련하는 동안에는 상수로 남아 있는다.  \n",
    "\n",
    "  \n",
    "- 훈련 데이터 과소적합(Underfitting)  \n",
    "과대적합의 반대. 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생.  \n",
    "해결 방법은 다음과 같다.\n",
    "    - 모델 파라미터가 더 많은 강력한 모델을 선택한다.\n",
    "    - 학습 알고리즘에 더 좋은 특성을 제공한다.\n",
    "    - 모델의 제약을 줄인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test & Validation\n",
    "모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 유일한 방법은 새로운 샘플에 실제로 적용해 보는 것.  \n",
    "(Training 시킨 model을 Test data를 통해 결과치를 확인하는 것.)\n",
    "\n",
    "\n",
    "더 좋은 방법은 훈련 데이터를 훈련 세트와 테스트 세트 두 개로 나누는 것이다. **(Training dataset + Test dataset)**  \n",
    "새로운 샘플에 대한 오류 비율을 일반화 오차(generalization error) 또는 외부 샘플 오차(out-of-sample error)라고 하며,  \n",
    "테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값(estimation)을 얻는다.  \n",
    "\n",
    "이 값은 이전에 본 적이 없는 새로운 샘플에 model이 얼마나 잘 작동할지 알려준다.\n",
    "(training이 끝난 model에 Test dataset을 input해 evaluation과정을 진행하면 일반화가 잘되었는지 확인할 수 있음.)\n",
    "\n",
    "\n",
    "**훈련 오차가 낮지만 일반화 오차가 높다면,(training loss는 낮은데 evaluation error가 높다면) 이는 모델이 훈련데이터에 과적합(overfitting)되었다는 뜻이다.**\n",
    "\n",
    "데이터셋의 크기에 따라 다르지만, 보통 데이터의 80%를 훈련에 사용하고, 20%는 테스트용으로 떼어놓는다.  \n",
    "천만개의 샘플이 있다면 여기서 1%만 떼어도 100,000개의 test 데이터가 있다는 의미니까."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning + model 선택\n",
    "모델 평가는 매우 간단하다. 그냥 Test set을 사용하면 된다.  \n",
    "두 모델 중 어떤 것을 선택할지 고민하고 있을 때, 두 모델 모두 훈련 세트로 훈련하고 테스트 세트를 사용해 얼마나 잘 일반화되는지 비교해보면 된다.\n",
    "\n",
    "선택한 모델에 과대 적합을 피하기 위해 규제를 적용하려고 한다.  \n",
    "이때 하이퍼파라미터 값을 어떻게 선택해야할까?? 100개의 하이퍼 파라미터 값으로 100개의 다른 모델을 훈련시키는 방법이 있다.  \n",
    "일반화 오차가 가장 낮은 모델을 만드는 최적의 하이퍼파라미터를 찾았다고 가정하자.  \n",
    "이제 이 모델을 실제 서비스에 투입했지만, 성능이 예상만큼 좋지 않고 오차가 발생했다. 왜 그럴까??  \n",
    "\n",
    "일반화 오차를 test set에서 여러 번 측정했으므로 모델과 하이퍼파라미터가 test set에 최적화된 모델을 만들었기 때문.  \n",
    "이는 모델이 새로운 데이터에 잘 작동하지 않을 수 있다.  \n",
    "\n",
    "이 문제에 대한 일반적인 해결 방법은 **홀드아웃 검증(holdout validation)**이다.  \n",
    "간단하게 훈련세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택한다. 이 새로운 홀드아웃 세트를 **검증세트(validation set)**이라 부른다.  \n",
    "**구체적으로 말하면 훈련세트에서 검증세트를 뺀 데이터에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련하고,  \n",
    "검증 세트에서 가장 높은 성능을 내는 모델을 선택한다. 이 과정이 끝나면 최선의 모델을 trainset + validation set으로 구성된 dataset으로 training하고, test dataset으로 평가하고 일반화 오차를 추정한다.**\n",
    "\n",
    "validation set이 너무 작으면 모델이 정확하게 평가되지 않을 것이기 때문에, 최적이 아닌 모델을 잘못 선택할 수 있다.\n",
    "반대로 검증세트가 너무 크면 남은 훈련 세트가 전체 훈련 세트보다 너무 작아진다. 최종 모델이 전체 훈련세트에서 훈련되기 때문에 너무 작은 훈련세트에서 훈련한 후보 모델을 비교하는 것은 이상적이지 않다.  \n",
    "이를 해결하기 위해서 작은 검증 세트 여러 개를 사용해 반복적인 교차 검증(cross-validation)을 수행하는 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit36bb2ec7fb134cbc86006216f283ed12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}