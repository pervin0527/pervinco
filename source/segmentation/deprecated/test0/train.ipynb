{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 1:\n",
    "    try:\n",
    "        print(\"Activate Multi GPU\")\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        print(\"Activate Sigle GPU\")\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AtrousSpatialPyramidPooling(model_input):\n",
    "  dims = tf.keras.backend.int_shape(model_input)\n",
    "\n",
    "  layer = tf.keras.layers.AveragePooling2D(pool_size=(dims[-3],\n",
    "                                                      dims[-2]))(model_input)\n",
    "  layer = tf.keras.layers.Conv2D(256, kernel_size=1, padding='same',\n",
    "                                 kernel_initializer = 'he_normal')(layer)\n",
    "  layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "  layer = tf.keras.layers.ReLU()(layer)\n",
    "  out_pool = tf.keras.layers.UpSampling2D(size = (dims[-3] // layer.shape[1],\n",
    "                                               dims[-2] // layer.shape[2]),\n",
    "                                        interpolation = 'bilinear')(layer)\n",
    "  \n",
    "  layer = tf.keras.layers.Conv2D(256, kernel_size = 1,\n",
    "                                   dilation_rate = 1, padding = 'same',\n",
    "                                   kernel_initializer = 'he_normal',\n",
    "                                   use_bias = False)(model_input)\n",
    "  layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "  out_1 = tf.keras.layers.ReLU()(layer)\n",
    "\n",
    "  layer = tf.keras.layers.Conv2D(256, kernel_size = 3,\n",
    "                                   dilation_rate = 6, padding = 'same', \n",
    "                                   kernel_initializer = 'he_normal',\n",
    "                                   use_bias = False)(model_input)\n",
    "  layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "  out_6 = tf.keras.layers.ReLU()(layer)\n",
    "\n",
    "  layer = tf.keras.layers.Conv2D(256, kernel_size = 3,\n",
    "                                   dilation_rate = 12, padding = 'same',\n",
    "                                   kernel_initializer = 'he_normal',\n",
    "                                   use_bias = False)(model_input)\n",
    "  layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "  out_12 = tf.keras.layers.ReLU()(layer)\n",
    "\n",
    "  layer = tf.keras.layers.Conv2D(256, kernel_size = 3,\n",
    "                                   dilation_rate = 18, padding = 'same',\n",
    "                                   kernel_initializer = 'he_normal',\n",
    "                                   use_bias = False)(model_input)\n",
    "  layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "  out_18 = tf.keras.layers.ReLU()(layer)\n",
    "\n",
    "  layer = tf.keras.layers.Concatenate(axis = -1)([out_pool, out_1,\n",
    "                                                    out_6, out_12,\n",
    "                                                    out_18])\n",
    "\n",
    "  layer = tf.keras.layers.Conv2D(256, kernel_size = 1,\n",
    "                                   dilation_rate = 1, padding = 'same',\n",
    "                                   kernel_initializer = 'he_normal',\n",
    "                                   use_bias = False)(layer)\n",
    "  layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "  model_output = tf.keras.layers.ReLU()(layer)\n",
    "  return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeeplabV3Plus(nclasses = 20, final_activation=None):\n",
    "  model_input = tf.keras.Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "  resnet50 = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_tensor = model_input)\n",
    "  layer = resnet50.get_layer('conv4_block6_2_relu').output\n",
    "  layer = AtrousSpatialPyramidPooling(layer)\n",
    "  input_a = tf.keras.layers.UpSampling2D(size = (IMG_SIZE // 4 // layer.shape[1], IMG_SIZE // 4 // layer.shape[2]), interpolation = 'bilinear')(layer)\n",
    "\n",
    "  input_b = resnet50.get_layer('conv2_block3_2_relu').output\n",
    "  input_b = tf.keras.layers.Conv2D(48, kernel_size = (1,1), padding = 'same', kernel_initializer = tf.keras.initializers.he_normal(), use_bias = False)(input_b)\n",
    "  input_b = tf.keras.layers.BatchNormalization()(input_b)\n",
    "  input_b = tf.keras.layers.ReLU()(input_b)\n",
    "\n",
    "  layer = tf.keras.layers.Concatenate(axis = -1)([input_a, input_b])\n",
    "\n",
    "  layer = tf.keras.layers.Conv2D(256, kernel_size = 3, padding = 'same', activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal(), use_bias = False)(layer)\n",
    "  layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "  layer = tf.keras.layers.ReLU()(layer)\n",
    "  layer = tf.keras.layers.Conv2D(256, kernel_size =3, padding = 'same', activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal(), use_bias = False)(layer)\n",
    "  layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "  layer = tf.keras.layers.ReLU()(layer)\n",
    "  layer = tf.keras.layers.UpSampling2D(size = (IMG_SIZE // layer.shape[1], IMG_SIZE // layer.shape[2]), interpolation = 'bilinear')(layer)\n",
    "\n",
    "  if final_activation == None:\n",
    "    model_output = tf.keras.layers.Conv2D(len(CLASSES), kernel_size = (1,1), padding = 'same')(layer)\n",
    "  \n",
    "  elif final_activation == \"softmax\":\n",
    "    layer = tf.keras.layers.Conv2D(len(CLASSES), kernel_size = (1,1), padding = 'same')(layer)\n",
    "    model_output = tf.keras.layers.Activation(\"softmax\")(layer)\n",
    "\n",
    "  return tf.keras.Model(inputs = model_input, outputs = model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(masks):\n",
    "    image_files = []\n",
    "    for mask in masks:\n",
    "        file_name = mask.split('/')[-1].split('.')[0]\n",
    "        if os.path.isfile(f\"{images}/{file_name}.jpg\"):\n",
    "            image_files.append(f\"{images}/{file_name}.jpg\")\n",
    "\n",
    "    return image_files\n",
    "\n",
    "def get_file_list(path):\n",
    "    images = sorted(glob(f\"{path}/images/*.jpg\"))\n",
    "    masks = sorted(glob(f\"{path}/masks/*.png\"))\n",
    "    \n",
    "    n_images, n_masks = len(images), len(masks)\n",
    "    \n",
    "    return images, masks, n_images, n_masks\n",
    "\n",
    "def read_image(image_path, mask=False):\n",
    "    image = tf.io.read_file(image_path)\n",
    "\n",
    "    if mask:\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image.set_shape([None, None, 1])\n",
    "        image = tf.image.resize(images=image, size=[IMG_SIZE, IMG_SIZE])\n",
    "\n",
    "    else:\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        image.set_shape([None, None, 3])\n",
    "        image = tf.image.resize(images=image, size=[IMG_SIZE, IMG_SIZE])\n",
    "        # image = image / 127.5 - 1\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_data(image_list, mask_list):\n",
    "    image = read_image(image_list)\n",
    "    mask = read_image(mask_list, mask=True)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def data_generator(image_list, mask_list):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, image_tensor):\n",
    "    predictions = model.predict(np.expand_dims((image_tensor), axis=0))\n",
    "    predictions = np.squeeze(predictions)\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def decode_segmentation_masks(mask, colormap, n_classes):\n",
    "    r = np.zeros_like(mask).astype(np.uint8)\n",
    "    g = np.zeros_like(mask).astype(np.uint8)\n",
    "    b = np.zeros_like(mask).astype(np.uint8)\n",
    "    for l in range(0, n_classes):\n",
    "        idx = mask == l\n",
    "        r[idx] = colormap[l, 0]\n",
    "        g[idx] = colormap[l, 1]\n",
    "        b[idx] = colormap[l, 2]\n",
    "    rgb = np.stack([r, g, b], axis=2)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def get_overlay(image, colored_mask):\n",
    "    image = tf.keras.preprocessing.image.array_to_img(image)\n",
    "    image = np.array(image).astype(np.uint8)\n",
    "    overlay = cv2.addWeighted(image, 0.35, colored_mask, 0.65, 0)\n",
    "\n",
    "    return overlay\n",
    "\n",
    "\n",
    "def plot_samples_matplotlib(display_list, idx, figsize=(5, 3)):\n",
    "    if not os.path.isdir(\"./train_result\"):\n",
    "        os.makedirs(\"./train_result\")\n",
    "\n",
    "    _, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
    "    for i in range(len(display_list)):\n",
    "        if display_list[i].shape[-1] == 3:\n",
    "            axes[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        else:\n",
    "            axes[i].imshow(display_list[i])\n",
    "\n",
    "    plt.savefig(f\"./train_result/result_{idx}.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_predictions(images_list, colormap, model):\n",
    "    for idx, image_file in enumerate(images_list):\n",
    "        image_tensor = read_image(image_file)\n",
    "        prediction_mask = infer(image_tensor=image_tensor, model=model)\n",
    "        prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, NUM_CLASSES)\n",
    "        overlay = get_overlay(image_tensor, prediction_colormap)\n",
    "        plot_samples_matplotlib([image_tensor, overlay, prediction_colormap], idx, figsize=(18, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # idx = np.random.randint(len(valid_images))\n",
    "        # plot_predictions([valid_images[idx]], colormap, model=model)\n",
    "        \n",
    "        plot_predictions(valid_images[:4], COLORMAP, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/data/Datasets/VOCdevkit/VOC2012\"\n",
    "LABEL_PATH = f\"{ROOT}/Labels/class_labels.txt\"\n",
    "SAVE_PATH = \"/data/Models/segmentation\"\n",
    "IS_SPLIT = True\n",
    "FOLDER = \"custom-softmax\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "IMG_SIZE = 512\n",
    "LEARNING_RATE = 0.001\n",
    "SAVE_NAME = f\"segmentation-sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(LABEL_PATH, sep='\\n', header=None, index_col=False)\n",
    "CLASSES = label_df[0].to_list()\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "print(CLASSES)\n",
    "\n",
    "COLORMAP = [[0, 0, 0],\n",
    "        [128, 0, 0],\n",
    "        [0, 128, 0],\n",
    "        [128, 128, 0],\n",
    "        [0, 0, 128],\n",
    "        [128, 0, 128],\n",
    "        [0, 128, 128],\n",
    "        [128, 128, 128],\n",
    "        [64, 0, 0],\n",
    "        [192, 0, 0],\n",
    "        [64, 128, 0],\n",
    "        [192, 128, 0],\n",
    "        [64, 0, 128],\n",
    "        [192, 0, 128],\n",
    "        [64, 128, 128],\n",
    "        [192, 128, 128],\n",
    "        [0, 64, 0],\n",
    "        [128, 64, 0],\n",
    "        [0, 192, 0],\n",
    "        [128, 192, 0],\n",
    "        [0, 64, 128]]\n",
    "COLORMAP = np.array(COLORMAP, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_SPLIT:\n",
    "    root = f\"{ROOT}/{FOLDER}\"\n",
    "    train_dir = f\"{root}/train\"\n",
    "    valid_dir = f\"{root}/valid\"\n",
    "\n",
    "    train_images, train_masks, n_train_images, n_train_masks = get_file_list(train_dir)\n",
    "    valid_images, valid_masks, n_valid_images, n_valid_masks = get_file_list(valid_dir)\n",
    "\n",
    "else:\n",
    "    root = f\"{ROOT}\"\n",
    "    masks = sorted(glob(f\"{root}/SegmentationRaw/*.png\"))\n",
    "    images = f\"{root}/JPEGImages\"\n",
    "\n",
    "    images = get_images(masks)\n",
    "    print(len(images), len(masks))\n",
    "\n",
    "    train_images, valid_images, train_masks, valid_masks = train_test_split(images, masks, test_size=0.1, shuffle=True, random_state=42)\n",
    "    print(len(train_images), len(train_masks))\n",
    "    print(len(valid_images), len(valid_masks))\n",
    "\n",
    "\n",
    "train_dataset = data_generator(train_images, train_masks)\n",
    "valid_dataset = data_generator(valid_images, valid_masks)\n",
    "\n",
    "print(\"Train Dataset:\", train_dataset)\n",
    "print(\"Val Dataset:\", valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeeplabV3Plus(nclasses=len(CLASSES), final_activation=\"softmax\")\n",
    "model.summary()\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_STEPS_PER_EPOCH = int(tf.math.ceil(len(train_images) / BATCH_SIZE).numpy())\n",
    "VALID_STEPS_PER_EPOCH = int(tf.math.ceil(len(valid_images) / BATCH_SIZE).numpy())\n",
    "\n",
    "callbacks = [DisplayCallback(),\n",
    "                tf.keras.callbacks.ModelCheckpoint(f\"{SAVE_PATH}/{SAVE_NAME}/best.ckpt\", 'val_loss', verbose=1, save_best_only=True, save_weights_only=True)]\n",
    "            \n",
    "history = model.fit(train_dataset,\n",
    "                    steps_per_epoch=TRAIN_STEPS_PER_EPOCH,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=VALID_STEPS_PER_EPOCH,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1,\n",
    "                    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(valid_images[:4], COLORMAP, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = tf.function(lambda x : model(x))\n",
    "batch_size = 1\n",
    "input_size = IMG_SIZE\n",
    "\n",
    "concrete_func = run_model.get_concrete_function(tf.TensorSpec([batch_size, input_size, input_size, 3], model.inputs[0].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.saved_model.save(model, '/data/Models/segmentation/saved_model')\n",
    "tf.saved_model.save(model, f'{SAVE_PATH}/{SAVE_NAME}/saved_model', signatures=concrete_func)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
