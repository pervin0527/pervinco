{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 1:\n",
    "    try:\n",
    "        print(\"Activate Multi GPU\")\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        print(\"Activate Sigle GPU\")\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = tf.keras.layers.UpSampling2D(size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",)(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = tf.keras.Input(shape=(image_size, image_size, 3))\n",
    "    resnet50 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_tensor=model_input)\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = tf.keras.layers.UpSampling2D(size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]), interpolation=\"bilinear\",)(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size=(image_size // x.shape[1], image_size // x.shape[2]), interpolation=\"bilinear\",)(x)\n",
    "    model_output = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=model_input, outputs=model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(path):\n",
    "    images = sorted(glob(f\"{path}/images/*.jpg\"))\n",
    "    masks = sorted(glob(f\"{path}/masks/*.png\"))\n",
    "    \n",
    "    n_images, n_masks = len(images), len(masks)\n",
    "    \n",
    "    return images, masks, n_images, n_masks\n",
    "\n",
    "\n",
    "def read_image(image_path, mask=False):\n",
    "    image = tf.io.read_file(image_path)\n",
    "\n",
    "    if mask:\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image.set_shape([None, None, 1])\n",
    "        image = tf.image.resize(images=image, size=[IMG_SIZE, IMG_SIZE])\n",
    "\n",
    "    else:\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        image.set_shape([None, None, 3])\n",
    "        image = tf.image.resize(images=image, size=[IMG_SIZE, IMG_SIZE])\n",
    "#         image = image / 127.5 - 1\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_data(image_list, mask_list):\n",
    "    image = read_image(image_list)\n",
    "    mask = read_image(mask_list, mask=True)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def data_generator(image_list, mask_list):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, image_tensor):\n",
    "    predictions = model.predict(np.expand_dims((image_tensor), axis=0))\n",
    "    predictions = np.squeeze(predictions)\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def decode_segmentation_masks(mask, colormap, n_classes):\n",
    "    r = np.zeros_like(mask).astype(np.uint8)\n",
    "    g = np.zeros_like(mask).astype(np.uint8)\n",
    "    b = np.zeros_like(mask).astype(np.uint8)\n",
    "    for l in range(0, n_classes):\n",
    "        idx = mask == l\n",
    "        r[idx] = colormap[l, 0]\n",
    "        g[idx] = colormap[l, 1]\n",
    "        b[idx] = colormap[l, 2]\n",
    "    rgb = np.stack([r, g, b], axis=2)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def get_overlay(image, colored_mask):\n",
    "    image = tf.keras.preprocessing.image.array_to_img(image)\n",
    "    image = np.array(image).astype(np.uint8)\n",
    "    overlay = cv2.addWeighted(image, 0.35, colored_mask, 0.65, 0)\n",
    "\n",
    "    return overlay\n",
    "\n",
    "\n",
    "def plot_samples_matplotlib(display_list, figsize=(5, 3)):\n",
    "    _, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
    "    for i in range(len(display_list)):\n",
    "        if display_list[i].shape[-1] == 3:\n",
    "            axes[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        else:\n",
    "            axes[i].imshow(display_list[i])\n",
    "    plt.show()\n",
    "    # plt.savefig(\"./result.png\")\n",
    "\n",
    "\n",
    "def plot_predictions(images_list, colormap, model):\n",
    "    for image_file in images_list:\n",
    "        image_tensor = read_image(image_file)\n",
    "        prediction_mask = infer(image_tensor=image_tensor, model=model)\n",
    "        prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, NUM_CLASSES)\n",
    "        overlay = get_overlay(image_tensor, prediction_colormap)\n",
    "        plot_samples_matplotlib([image_tensor, overlay, prediction_colormap], figsize=(18, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # idx = np.random.randint(len(valid_images))\n",
    "        # plot_predictions([valid_images[idx]], colormap, model=model)\n",
    "\n",
    "        plot_predictions(valid_images[:4], colormap, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_curves(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(history.history['loss']))\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(masks):\n",
    "    image_files = []\n",
    "    for mask in masks:\n",
    "        file_name = mask.split('/')[-1].split('.')[0]\n",
    "        if os.path.isfile(f\"{images}/{file_name}.jpg\"):\n",
    "            image_files.append(f\"{images}/{file_name}.jpg\")\n",
    "\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 300\n",
    "IMG_SIZE = 320\n",
    "LEARNING_RATE = 0.00001\n",
    "IS_SPLIT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = [[0, 0, 0],\n",
    "            [128, 0, 0],\n",
    "            [0, 128, 0],\n",
    "            [128, 128, 0],\n",
    "            [0, 0, 128],\n",
    "            [128, 0, 128],\n",
    "            [0, 128, 128],\n",
    "            [128, 128, 128],\n",
    "            [64, 0, 0],\n",
    "            [192, 0, 0],\n",
    "            [64, 128, 0],\n",
    "            [192, 128, 0],\n",
    "            [64, 0, 128],\n",
    "            [192, 0, 128],\n",
    "            [64, 128, 128],\n",
    "            [192, 128, 128],\n",
    "            [0, 64, 0],\n",
    "            [128, 64, 0],\n",
    "            [0, 192, 0],\n",
    "            [128, 192, 0],\n",
    "            [0, 64, 128]]\n",
    "\n",
    "colormap = np.array(colormap, dtype=np.uint8)\n",
    "\n",
    "CLASSES = [\"background\", \n",
    "           \"aeroplane\",\n",
    "           \"bicycle\",\n",
    "           \"bird\",\n",
    "           \"boat\",\n",
    "           \"bottle\",\n",
    "           \"bus\",\n",
    "           \"car\",\n",
    "           \"cat\",\n",
    "           \"chair\",\n",
    "           \"cow\", \n",
    "           \"diningtable\",\n",
    "           \"dog\",\n",
    "           \"horse\",\n",
    "           \"motorbike\",\n",
    "           \"person\",\n",
    "           \"potted plant\",\n",
    "           \"sheep\",\n",
    "           \"sofa\",\n",
    "           \"train\",\n",
    "           \"tv/monitor\"]\n",
    "            \n",
    "NUM_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_SPLIT:\n",
    "    root = \"/data/Datasets/VOCtrainval_11-May-2012/VOCdevkit/VOC2012/Segmentation\"\n",
    "    train_dir = f\"{root}/train\"\n",
    "    valid_dir = f\"{root}/valid\"\n",
    "\n",
    "    train_images, train_masks, n_train_images, n_train_masks = get_file_list(train_dir)\n",
    "    valid_images, valid_masks, n_valid_images, n_valid_masks = get_file_list(valid_dir)\n",
    "\n",
    "else:\n",
    "    root = \"/data/Datasets/VOCtrainval_11-May-2012/VOCdevkit/VOC2012\"\n",
    "    masks = sorted(glob(f\"{root}/SegmentationRaw/*.png\"))\n",
    "    images = f\"{root}/JPEGImages\"\n",
    "\n",
    "    images = get_images(masks)\n",
    "    print(len(images), len(masks))\n",
    "\n",
    "    train_images, valid_images, train_masks, valid_masks = train_test_split(images, masks, test_size=0.1, shuffle=True, random_state=42)\n",
    "    print(len(train_images), len(train_masks))\n",
    "    print(len(valid_images), len(valid_masks))\n",
    "\n",
    "\n",
    "train_dataset = data_generator(train_images, train_masks)\n",
    "valid_dataset = data_generator(valid_images, valid_masks)\n",
    "\n",
    "print(\"Train Dataset:\", train_dataset)\n",
    "print(\"Val Dataset:\", valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeeplabV3Plus(image_size=IMG_SIZE, num_classes=NUM_CLASSES)\n",
    "model.summary()\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_STEPS_PER_EPOCH = int(tf.math.ceil(len(train_images) / BATCH_SIZE).numpy())\n",
    "VALID_STEPS_PER_EPOCH = int(tf.math.ceil(len(valid_images) / BATCH_SIZE).numpy())\n",
    "\n",
    "callbacks = [DisplayCallback()]\n",
    "             \n",
    "history = model.fit(train_dataset,\n",
    "                    steps_per_epoch=TRAIN_STEPS_PER_EPOCH,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=VALID_STEPS_PER_EPOCH,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1,\n",
    "                    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_training_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(valid_images[:4], colormap, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = tf.function(lambda x : model(x))\n",
    "batch_size = 1\n",
    "input_size = IMG_SIZE\n",
    "\n",
    "concrete_func = run_model.get_concrete_function(tf.TensorSpec([batch_size, input_size, input_size, 3], model.inputs[0].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.saved_model.save(model, '/data/Models/segmentation/saved_model')\n",
    "tf.saved_model.save(model, '/data/Models/segmentation/saved_model', signatures=concrete_func)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
