{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model import Deeplabv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 1:\n",
    "    try:\n",
    "        print(\"Activate Multi GPU\")\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        print(\"Activate Sigle GPU\")\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(path):\n",
    "    images = sorted(glob(f\"{path}/images/*.jpg\"))\n",
    "    masks = sorted(glob(f\"{path}/masks/*.png\"))\n",
    "    \n",
    "    n_images, n_masks = len(images), len(masks)\n",
    "    \n",
    "    return images, masks, n_images, n_masks\n",
    "\n",
    "\n",
    "def read_image(image_path, mask=False):\n",
    "    image = tf.io.read_file(image_path)\n",
    "\n",
    "    if mask:\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image.set_shape([None, None, 1])\n",
    "        image = tf.image.resize(images=image, size=[IMG_SIZE, IMG_SIZE])\n",
    "\n",
    "    else:\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        image.set_shape([None, None, 3])\n",
    "        image = tf.image.resize(images=image, size=[IMG_SIZE, IMG_SIZE])\n",
    "        # image = image / 127.5 - 1\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_data(image_list, mask_list):\n",
    "    image = read_image(image_list)\n",
    "    mask = read_image(mask_list, mask=True)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def data_generator(image_list, mask_list):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, image_tensor):\n",
    "    predictions = model.predict(np.expand_dims((image_tensor), axis=0))\n",
    "    predictions = np.squeeze(predictions)\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def decode_segmentation_masks(mask, colormap, n_classes):\n",
    "    r = np.zeros_like(mask).astype(np.uint8)\n",
    "    g = np.zeros_like(mask).astype(np.uint8)\n",
    "    b = np.zeros_like(mask).astype(np.uint8)\n",
    "    for l in range(0, n_classes):\n",
    "        idx = mask == l\n",
    "        r[idx] = colormap[l, 0]\n",
    "        g[idx] = colormap[l, 1]\n",
    "        b[idx] = colormap[l, 2]\n",
    "    rgb = np.stack([r, g, b], axis=2)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def get_overlay(image, colored_mask):\n",
    "    image = tf.keras.preprocessing.image.array_to_img(image)\n",
    "    image = np.array(image).astype(np.uint8)\n",
    "    overlay = cv2.addWeighted(image, 0.35, colored_mask, 0.65, 0)\n",
    "\n",
    "    return overlay\n",
    "\n",
    "\n",
    "def plot_samples_matplotlib(display_list, idx, figsize=(5, 3)):\n",
    "    if not os.path.isdir(\"./train_result\"):\n",
    "        os.makedirs(\"./train_result\")\n",
    "\n",
    "    _, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
    "    for i in range(len(display_list)):\n",
    "        if display_list[i].shape[-1] == 3:\n",
    "            axes[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        else:\n",
    "            axes[i].imshow(display_list[i])\n",
    "\n",
    "    plt.savefig(f\"./train_result/result_{idx}.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_predictions(images_list, colormap, model):\n",
    "    for idx, image_file in enumerate(images_list):\n",
    "        image_tensor = read_image(image_file)\n",
    "        prediction_mask = infer(image_tensor=image_tensor, model=model)\n",
    "        prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, NUM_CLASSES)\n",
    "        overlay = get_overlay(image_tensor, prediction_colormap)\n",
    "        plot_samples_matplotlib([image_tensor, overlay, prediction_colormap], idx, figsize=(18, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_curves(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(history.history['loss']))\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.savefig(f\"./train_result/train_history.png\")\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def get_images(masks):\n",
    "    image_files = []\n",
    "    for mask in masks:\n",
    "        file_name = mask.split('/')[-1].split('.')[0]\n",
    "        if os.path.isfile(f\"{images}/{file_name}.jpg\"):\n",
    "            image_files.append(f\"{images}/{file_name}.jpg\")\n",
    "\n",
    "    return image_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # idx = np.random.randint(len(valid_images))\n",
    "        # plot_predictions([valid_images[idx]], colormap, model=model)\n",
    "        \n",
    "        plot_predictions(valid_images[:4], COLORMAP, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/data/Datasets/VOCtrainval_11-May-2012/VOCdevkit/VOC2012\"\n",
    "LABEL_PATH = f\"{ROOT}/Labels/class_labels.txt\"\n",
    "SAVE_PATH = \"/data/Models/segmentation-sample\"\n",
    "IS_SPLIT = True\n",
    "FOLDER = \"Augmentation-sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "IMG_SIZE = 320\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "label_df = pd.read_csv(LABEL_PATH, lineterminator=\"\\n\", header=None, index_col=False)\n",
    "CLASSES = label_df[0].to_list()\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "print(CLASSES)\n",
    "\n",
    "COLORMAP = [[0, 0, 0],\n",
    "            [128, 0, 0],\n",
    "            [0, 128, 0],\n",
    "            [128, 128, 0],\n",
    "            [0, 0, 128],\n",
    "            [128, 0, 128],\n",
    "            [0, 128, 128],\n",
    "            [128, 128, 128],\n",
    "            [64, 0, 0],\n",
    "            [192, 0, 0],\n",
    "            [64, 128, 0],\n",
    "            [192, 128, 0],\n",
    "            [64, 0, 128],\n",
    "            [192, 0, 128],\n",
    "            [64, 128, 128],\n",
    "            [192, 128, 128],\n",
    "            [0, 64, 0],\n",
    "            [128, 64, 0],\n",
    "            [0, 192, 0],\n",
    "            [128, 192, 0],\n",
    "            [0, 64, 128]]\n",
    "COLORMAP = np.array(COLORMAP, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_SPLIT:\n",
    "    root = f\"{ROOT}/{FOLDER}\"\n",
    "    train_dir = f\"{root}/train\"\n",
    "    valid_dir = f\"{root}/valid\"\n",
    "\n",
    "    train_images, train_masks, n_train_images, n_train_masks = get_file_list(train_dir)\n",
    "    valid_images, valid_masks, n_valid_images, n_valid_masks = get_file_list(valid_dir)\n",
    "\n",
    "else:\n",
    "    root = f\"{ROOT}\"\n",
    "    masks = sorted(glob(f\"{root}/SegmentationRaw/*.png\"))\n",
    "    images = f\"{root}/JPEGImages\"\n",
    "\n",
    "    images = get_images(masks)\n",
    "    print(len(images), len(masks))\n",
    "\n",
    "    train_images, valid_images, train_masks, valid_masks = train_test_split(images, masks, test_size=0.1, shuffle=True, random_state=42)\n",
    "    print(len(train_images), len(train_masks))\n",
    "    print(len(valid_images), len(valid_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_generator(train_images, train_masks)\n",
    "valid_dataset = data_generator(valid_images, valid_masks)\n",
    "\n",
    "print(\"Train Dataset:\", train_dataset)\n",
    "print(\"Val Dataset:\", valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### weights : \"pascal_voc\", \"cityscapes\", None\n",
    "# model = Deeplabv3(weights=\"pascal_voc\", input_tensor=None, input_shape=(IMG_SIZE, IMG_SIZE, 3), classes=len(CLASSES), backbone='xception', OS=16, alpha=1., activation=None)\n",
    "model = Deeplabv3(weights=\"cityscapes\", input_tensor=None, input_shape=(IMG_SIZE, IMG_SIZE, 3), classes=len(CLASSES), backbone='xception', OS=16, alpha=1., activation=None)\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    # print(layer.name + \": \" + str(layer.trainable))\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss=loss, metrics=[\"accuracy\"])\n",
    "# model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE, momentum=0.9), loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_STEPS_PER_EPOCH = int(tf.math.ceil(len(train_images) / BATCH_SIZE).numpy())\n",
    "VALID_STEPS_PER_EPOCH = int(tf.math.ceil(len(valid_images) / BATCH_SIZE).numpy())\n",
    "\n",
    "callbacks = [DisplayCallback(),\n",
    "             tf.keras.callbacks.ModelCheckpoint(f\"{SAVE_PATH}/saved_model/deeplabv3+.ckpt\", 'val_loss', verbose=1, save_best_only=True, save_weights_only=True)]\n",
    "            \n",
    "history = model.fit(train_dataset,\n",
    "                    steps_per_epoch=TRAIN_STEPS_PER_EPOCH,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=VALID_STEPS_PER_EPOCH,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1,\n",
    "                    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_training_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Deeplabv3(weights=None, input_tensor=None, input_shape=(IMG_SIZE, IMG_SIZE, 3), classes=len(CLASSES), backbone='xception', OS=8, alpha=1., activation=None)\n",
    "model.load_weights(f\"{SAVE_PATH}/saved_model/deeplabv3+.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(valid_images[:4], COLORMAP, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = tf.function(lambda x : model(x))\n",
    "batch_size = 1\n",
    "input_size = IMG_SIZE\n",
    "\n",
    "concrete_func = run_model.get_concrete_function(tf.TensorSpec([batch_size, input_size, input_size, 3], model.inputs[0].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.saved_model.save(model, f'{SAVE_PATH}/saved_model')\n",
    "tf.saved_model.save(model, f'{SAVE_PATH}/saved_model', signatures=concrete_func)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
